<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>bitrl Documentation: cuberl::rl::RLSerialAgentTrainer&lt; EnvType, AgentType &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">bitrl Documentation
   </div>
   <div id="projectbrief">Simulation engine for reinforcement learning agents</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespacecuberl.html">cuberl</a></li><li class="navelem"><a class="el" href="namespacecuberl_1_1rl.html">rl</a></li><li class="navelem"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">RLSerialAgentTrainer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classcuberl_1_1rl_1_1RLSerialAgentTrainer-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">cuberl::rl::RLSerialAgentTrainer&lt; EnvType, AgentType &gt; Class Template Reference</div></div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="rl__serial__agent__trainer_8h_source.html">rl_serial_agent_trainer.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for cuberl::rl::RLSerialAgentTrainer&lt; EnvType, AgentType &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classcuberl_1_1rl_1_1RLSerialAgentTrainer__inherit__graph.png" border="0" usemap="#acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_inherit__map" alt="Inheritance graph"/></div>
<map name="acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_inherit__map" id="acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_inherit__map">
<area shape="rect" title=" " alt="" coords="5,79,232,119"/>
<area shape="rect" title=" " alt="" coords="44,5,193,31"/>
<area shape="poly" title=" " alt="" coords="121,44,121,79,116,79,116,44"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for cuberl::rl::RLSerialAgentTrainer&lt; EnvType, AgentType &gt;:</div>
<div class="dyncontent">
<div class="center"><img src="classcuberl_1_1rl_1_1RLSerialAgentTrainer__coll__graph.png" border="0" usemap="#acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_coll__map" alt="Collaboration graph"/></div>
<map name="acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_coll__map" id="acuberl_1_1rl_1_1RLSerialAgentTrainer_3_01EnvType_00_01AgentType_01_4_coll__map">
<area shape="rect" title=" " alt="" coords="68,108,295,148"/>
<area shape="rect" title=" " alt="" coords="5,13,155,38"/>
<area shape="poly" title=" " alt="" coords="103,46,164,106,160,110,99,50"/>
<area shape="rect" href="classbitrl_1_1utils_1_1IterativeAlgorithmController.html" title="Controller for iterative algorithms." alt="" coords="179,5,389,45"/>
<area shape="poly" title=" " alt="" coords="257,57,202,110,199,106,253,53"/>
</map>
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-types" name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a198cdeb6c36c3642abb0dc8ce843b2c6" id="r_a198cdeb6c36c3642abb0dc8ce843b2c6"><td class="memItemLeft" align="right" valign="top">typedef EnvType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a></td></tr>
<tr class="separator:a198cdeb6c36c3642abb0dc8ce843b2c6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ace3958d75b323ae24cbca6890f8fceb5" id="r_ace3958d75b323ae24cbca6890f8fceb5"><td class="memItemLeft" align="right" valign="top">typedef AgentType&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ace3958d75b323ae24cbca6890f8fceb5">agent_type</a></td></tr>
<tr class="separator:ace3958d75b323ae24cbca6890f8fceb5"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a901927c074a532841b254d9e015808ef" id="r_a901927c074a532841b254d9e015808ef"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a901927c074a532841b254d9e015808ef">RLSerialAgentTrainer</a> (const <a class="el" href="structcuberl_1_1rl_1_1RLSerialTrainerConfig.html">RLSerialTrainerConfig</a> &amp;config, <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ace3958d75b323ae24cbca6890f8fceb5">agent_type</a> &amp;agent)</td></tr>
<tr class="memdesc:a901927c074a532841b254d9e015808ef"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">RLSerialAgentTrainer</a>.  <br /></td></tr>
<tr class="separator:a901927c074a532841b254d9e015808ef"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12267e345e16c33e54f93949697adf70" id="r_a12267e345e16c33e54f93949697adf70"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="structbitrl_1_1utils_1_1IterativeAlgorithmResult.html">bitrl::utils::IterativeAlgorithmResult</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a12267e345e16c33e54f93949697adf70">train</a> (<a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;env)</td></tr>
<tr class="memdesc:a12267e345e16c33e54f93949697adf70"><td class="mdescLeft">&#160;</td><td class="mdescRight">train Iterate to train the agent on the given environment  <br /></td></tr>
<tr class="separator:a12267e345e16c33e54f93949697adf70"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6b18a9c6756582ab641296b6088bed22" id="r_a6b18a9c6756582ab641296b6088bed22"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a6b18a9c6756582ab641296b6088bed22">actions_before_training_begins</a> (<a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;)</td></tr>
<tr class="memdesc:a6b18a9c6756582ab641296b6088bed22"><td class="mdescLeft">&#160;</td><td class="mdescRight">actions_before_training_begins. Execute any actions the algorithm needs before starting the episode  <br /></td></tr>
<tr class="separator:a6b18a9c6756582ab641296b6088bed22"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adc3650afe097b5bffa309cbd44ebd82a" id="r_adc3650afe097b5bffa309cbd44ebd82a"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#adc3650afe097b5bffa309cbd44ebd82a">actions_before_episode_begins</a> (<a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;, <a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>)</td></tr>
<tr class="memdesc:adc3650afe097b5bffa309cbd44ebd82a"><td class="mdescLeft">&#160;</td><td class="mdescRight">actions_before_episode_begins. Execute any actions the algorithm needs before starting the episode  <br /></td></tr>
<tr class="separator:adc3650afe097b5bffa309cbd44ebd82a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae5a4a75817043ea3960d075fa0a5a381" id="r_ae5a4a75817043ea3960d075fa0a5a381"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ae5a4a75817043ea3960d075fa0a5a381">actions_after_episode_ends</a> (<a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;, <a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>, const <a class="el" href="structcuberl_1_1rl_1_1EpisodeInfo.html">EpisodeInfo</a> &amp;einfo)</td></tr>
<tr class="memdesc:ae5a4a75817043ea3960d075fa0a5a381"><td class="mdescLeft">&#160;</td><td class="mdescRight">actions_after_episode_ends. Execute any actions the algorithm needs after ending the episode  <br /></td></tr>
<tr class="separator:ae5a4a75817043ea3960d075fa0a5a381"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6375d89cb30ce613d9064645ae783e2a" id="r_a6375d89cb30ce613d9064645ae783e2a"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a6375d89cb30ce613d9064645ae783e2a">actions_after_training_ends</a> (<a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;)</td></tr>
<tr class="memdesc:a6375d89cb30ce613d9064645ae783e2a"><td class="mdescLeft">&#160;</td><td class="mdescRight">actions_after_training_ends. Execute any actions the algorithm needs after the iterations are finished  <br /></td></tr>
<tr class="separator:a6375d89cb30ce613d9064645ae783e2a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3a85a91a07717d52c2e4bd4ede7e3f60" id="r_a3a85a91a07717d52c2e4bd4ede7e3f60"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; <a class="el" href="namespacebitrl.html#a2f4504e90084ab8d017fb11d685b01bb">real_t</a> &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a3a85a91a07717d52c2e4bd4ede7e3f60">episodes_total_rewards</a> () const noexcept</td></tr>
<tr class="memdesc:a3a85a91a07717d52c2e4bd4ede7e3f60"><td class="mdescLeft">&#160;</td><td class="mdescRight">episodes_total_rewards  <br /></td></tr>
<tr class="separator:a3a85a91a07717d52c2e4bd4ede7e3f60"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a240761bbe2d21e3dc80d40b1a5dc3c69" id="r_a240761bbe2d21e3dc80d40b1a5dc3c69"><td class="memItemLeft" align="right" valign="top">const std::vector&lt; <a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a> &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a240761bbe2d21e3dc80d40b1a5dc3c69">n_itrs_per_episode</a> () const noexcept</td></tr>
<tr class="memdesc:a240761bbe2d21e3dc80d40b1a5dc3c69"><td class="mdescLeft">&#160;</td><td class="mdescRight">n_itrs_per_episode  <br /></td></tr>
<tr class="separator:a240761bbe2d21e3dc80d40b1a5dc3c69"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a629d80e9564027417feed11ee926a38a" id="r_a629d80e9564027417feed11ee926a38a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a629d80e9564027417feed11ee926a38a">output_msg_frequency_</a></td></tr>
<tr class="separator:a629d80e9564027417feed11ee926a38a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae3bb05528d81410a9bddfc43191edf08" id="r_ae3bb05528d81410a9bddfc43191edf08"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classbitrl_1_1utils_1_1IterativeAlgorithmController.html">bitrl::utils::IterativeAlgorithmController</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ae3bb05528d81410a9bddfc43191edf08">itr_ctrl_</a></td></tr>
<tr class="memdesc:ae3bb05528d81410a9bddfc43191edf08"><td class="mdescLeft">&#160;</td><td class="mdescRight">itr_ctrl_ Handles the iteration over the episodes  <br /></td></tr>
<tr class="separator:ae3bb05528d81410a9bddfc43191edf08"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54ab81968ee17915140ff2600f5f44ae" id="r_a54ab81968ee17915140ff2600f5f44ae"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ace3958d75b323ae24cbca6890f8fceb5">agent_type</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a54ab81968ee17915140ff2600f5f44ae">agent_</a></td></tr>
<tr class="memdesc:a54ab81968ee17915140ff2600f5f44ae"><td class="mdescLeft">&#160;</td><td class="mdescRight">agent_  <br /></td></tr>
<tr class="separator:a54ab81968ee17915140ff2600f5f44ae"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a53ac0dbd6ec80c48e4a20e512cf43a6f" id="r_a53ac0dbd6ec80c48e4a20e512cf43a6f"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="namespacebitrl.html#a2f4504e90084ab8d017fb11d685b01bb">real_t</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a53ac0dbd6ec80c48e4a20e512cf43a6f">total_reward_per_episode_</a></td></tr>
<tr class="memdesc:a53ac0dbd6ec80c48e4a20e512cf43a6f"><td class="mdescLeft">&#160;</td><td class="mdescRight">total_reward_per_episode_  <br /></td></tr>
<tr class="separator:a53ac0dbd6ec80c48e4a20e512cf43a6f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac632a6cee5d64c131be2678dcbe0ffba" id="r_ac632a6cee5d64c131be2678dcbe0ffba"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ac632a6cee5d64c131be2678dcbe0ffba">n_itrs_per_episode_</a></td></tr>
<tr class="memdesc:ac632a6cee5d64c131be2678dcbe0ffba"><td class="mdescLeft">&#160;</td><td class="mdescRight">n_itrs_per_episode_ Holds the number of iterations performed per training episode  <br /></td></tr>
<tr class="separator:ac632a6cee5d64c131be2678dcbe0ffba"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><div class="compoundTemplParams">template&lt;typename EnvType, typename AgentType&gt;<br />
class cuberl::rl::RLSerialAgentTrainer&lt; EnvType, AgentType &gt;</div><p>\detailed The <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">RLSerialAgentTrainer</a> class handles the training for serial reinforcement learning agents </p>
</div><h2 class="groupheader">Member Typedef Documentation</h2>
<a id="ace3958d75b323ae24cbca6890f8fceb5" name="ace3958d75b323ae24cbca6890f8fceb5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ace3958d75b323ae24cbca6890f8fceb5">&#9670;&#160;</a></span>agent_type</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef AgentType <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::agent_type</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a198cdeb6c36c3642abb0dc8ce843b2c6" name="a198cdeb6c36c3642abb0dc8ce843b2c6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a198cdeb6c36c3642abb0dc8ce843b2c6">&#9670;&#160;</a></span>env_type</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">typedef EnvType <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::env_type</td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a901927c074a532841b254d9e015808ef" name="a901927c074a532841b254d9e015808ef"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a901927c074a532841b254d9e015808ef">&#9670;&#160;</a></span>RLSerialAgentTrainer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::RLSerialAgentTrainer </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structcuberl_1_1rl_1_1RLSerialTrainerConfig.html">RLSerialTrainerConfig</a> &amp;&#160;</td>
          <td class="paramname"><em>config</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ace3958d75b323ae24cbca6890f8fceb5">agent_type</a> &amp;&#160;</td>
          <td class="paramname"><em>agent</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">RLSerialAgentTrainer</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">config</td><td></td></tr>
    <tr><td class="paramname">agent</td><td></td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="ae5a4a75817043ea3960d075fa0a5a381" name="ae5a4a75817043ea3960d075fa0a5a381"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae5a4a75817043ea3960d075fa0a5a381">&#9670;&#160;</a></span>actions_after_episode_ends()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::actions_after_episode_ends </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;&#160;</td>
          <td class="paramname"><em>env</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>&#160;</td>
          <td class="paramname"><em>episode_idx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structcuberl_1_1rl_1_1EpisodeInfo.html">EpisodeInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>einfo</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>actions_after_episode_ends. Execute any actions the algorithm needs after ending the episode </p>

</div>
</div>
<a id="a6375d89cb30ce613d9064645ae783e2a" name="a6375d89cb30ce613d9064645ae783e2a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6375d89cb30ce613d9064645ae783e2a">&#9670;&#160;</a></span>actions_after_training_ends()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::actions_after_training_ends </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;&#160;</td>
          <td class="paramname"><em>env</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>actions_after_training_ends. Execute any actions the algorithm needs after the iterations are finished </p>

</div>
</div>
<a id="adc3650afe097b5bffa309cbd44ebd82a" name="adc3650afe097b5bffa309cbd44ebd82a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc3650afe097b5bffa309cbd44ebd82a">&#9670;&#160;</a></span>actions_before_episode_begins()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::actions_before_episode_begins </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;&#160;</td>
          <td class="paramname"><em>env</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>&#160;</td>
          <td class="paramname"><em>episode_idx</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>actions_before_episode_begins. Execute any actions the algorithm needs before starting the episode </p>

</div>
</div>
<a id="a6b18a9c6756582ab641296b6088bed22" name="a6b18a9c6756582ab641296b6088bed22"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6b18a9c6756582ab641296b6088bed22">&#9670;&#160;</a></span>actions_before_training_begins()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::actions_before_training_begins </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;&#160;</td>
          <td class="paramname"><em>env</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>actions_before_training_begins. Execute any actions the algorithm needs before starting the episode </p>

</div>
</div>
<a id="a3a85a91a07717d52c2e4bd4ede7e3f60" name="a3a85a91a07717d52c2e4bd4ede7e3f60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3a85a91a07717d52c2e4bd4ede7e3f60">&#9670;&#160;</a></span>episodes_total_rewards()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt; <a class="el" href="namespacebitrl.html#a2f4504e90084ab8d017fb11d685b01bb">real_t</a> &gt; &amp; <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::episodes_total_rewards </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>episodes_total_rewards </p>
<dl class="section return"><dt>Returns</dt><dd></dd></dl>

</div>
</div>
<a id="a240761bbe2d21e3dc80d40b1a5dc3c69" name="a240761bbe2d21e3dc80d40b1a5dc3c69"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a240761bbe2d21e3dc80d40b1a5dc3c69">&#9670;&#160;</a></span>n_itrs_per_episode()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const std::vector&lt; <a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a> &gt; &amp; <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::n_itrs_per_episode </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>n_itrs_per_episode </p>
<dl class="section return"><dt>Returns</dt><dd></dd></dl>

</div>
</div>
<a id="a12267e345e16c33e54f93949697adf70" name="a12267e345e16c33e54f93949697adf70"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12267e345e16c33e54f93949697adf70">&#9670;&#160;</a></span>train()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="structbitrl_1_1utils_1_1IterativeAlgorithmResult.html">bitrl::utils::IterativeAlgorithmResult</a> <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::train </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#a198cdeb6c36c3642abb0dc8ce843b2c6">env_type</a> &amp;&#160;</td>
          <td class="paramname"><em>env</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>train Iterate to train the agent on the given environment </p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a54ab81968ee17915140ff2600f5f44ae" name="a54ab81968ee17915140ff2600f5f44ae"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54ab81968ee17915140ff2600f5f44ae">&#9670;&#160;</a></span>agent_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html#ace3958d75b323ae24cbca6890f8fceb5">agent_type</a>&amp; <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::agent_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>agent_ </p>

</div>
</div>
<a id="ae3bb05528d81410a9bddfc43191edf08" name="ae3bb05528d81410a9bddfc43191edf08"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae3bb05528d81410a9bddfc43191edf08">&#9670;&#160;</a></span>itr_ctrl_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classbitrl_1_1utils_1_1IterativeAlgorithmController.html">bitrl::utils::IterativeAlgorithmController</a> <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::itr_ctrl_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>itr_ctrl_ Handles the iteration over the episodes </p>

</div>
</div>
<a id="ac632a6cee5d64c131be2678dcbe0ffba" name="ac632a6cee5d64c131be2678dcbe0ffba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac632a6cee5d64c131be2678dcbe0ffba">&#9670;&#160;</a></span>n_itrs_per_episode_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a>&gt; <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::n_itrs_per_episode_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>n_itrs_per_episode_ Holds the number of iterations performed per training episode </p>

</div>
</div>
<a id="a629d80e9564027417feed11ee926a38a" name="a629d80e9564027417feed11ee926a38a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a629d80e9564027417feed11ee926a38a">&#9670;&#160;</a></span>output_msg_frequency_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespacebitrl.html#a84c96b350ee9feed7262273146a5ad11">uint_t</a> <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::output_msg_frequency_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a53ac0dbd6ec80c48e4a20e512cf43a6f" name="a53ac0dbd6ec80c48e4a20e512cf43a6f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a53ac0dbd6ec80c48e4a20e512cf43a6f">&#9670;&#160;</a></span>total_reward_per_episode_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename EnvType , typename AgentType &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;<a class="el" href="namespacebitrl.html#a2f4504e90084ab8d017fb11d685b01bb">real_t</a>&gt; <a class="el" href="classcuberl_1_1rl_1_1RLSerialAgentTrainer.html">cuberl::rl::RLSerialAgentTrainer</a>&lt; EnvType, AgentType &gt;::total_reward_per_episode_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>total_reward_per_episode_ </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>libs/cuberl/include/cuberl/rl/trainers/<a class="el" href="rl__serial__agent__trainer_8h_source.html">rl_serial_agent_trainer.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
